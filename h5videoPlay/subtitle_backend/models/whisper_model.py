#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Faster-Whisper æ¨¡å‹å®ç°
"""
import time
import logging
import platform
from typing import Optional, Tuple
import numpy as np
from faster_whisper import WhisperModel

from .base_model import BaseSpeechToTextModel

logger = logging.getLogger(__name__)


class WhisperSTTModel(BaseSpeechToTextModel):
    """Faster-Whisper è¯­éŸ³è½¬æ–‡å­—æ¨¡å‹"""
    
    def __init__(self, config: dict):
        super().__init__(config)
        self.model_size = config.get('model_size', 'small')
        self.device = config.get('device', 'cpu')
        self.compute_type = config.get('compute_type', 'int8')
        self.cpu_threads = config.get('cpu_threads', 4)
        self.model: Optional[WhisperModel] = None
    
    def initialize(self):
        """åˆå§‹åŒ– Whisper æ¨¡å‹"""
        try:
            # è‡ªåŠ¨æ£€æµ‹è®¾å¤‡é…ç½®
            system = platform.system()
            if system == "Darwin":
                if self.model_size == "auto":
                    self.model_size = "small"
            elif system == "Windows":
                if self._check_cuda():
                    self.device = "cuda"
                    self.compute_type = "float16"
                    self.cpu_threads = 0
                    if self.model_size == "auto":
                        self.model_size = "deepdml/faster-whisper-large-v3-turbo-ct2"
                else:
                    if self.model_size == "auto":
                        self.model_size = "small"
            elif system == 'Linux':
                self.device = "cuda"
                self.compute_type = "int8"
                if self.model_size == "auto":
                    self.model_size = "small"
            
            logger.info(f"âš™ï¸ [Whisper] åŠ è½½æ¨¡å‹: {self.model_size} | {self.device} | {self.compute_type}")
            
            self.model = WhisperModel(
                self.model_size,
                device=self.device,
                compute_type=self.compute_type,
                cpu_threads=self.cpu_threads,
                num_workers=1
            )
            logger.info("âœ… [Whisper] æ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ [Whisper] æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
    
    def _check_cuda(self):
        """æ£€æŸ¥ CUDA æ˜¯å¦å¯ç”¨"""
        try:
            import ctypes
            ctypes.cdll.LoadLibrary('nvcuda.dll')
            return True
        except:
            return False
    
    def transcribe(
        self,
        audio_data: np.ndarray,
        sample_rate: int = 16000,
        language: Optional[str] = None,
        prompt: str = ""
    ) -> Tuple[Optional[str], Optional[str], float]:
        """è½¬å½•éŸ³é¢‘æ•°æ®"""
        if not self.model:
            logger.error("[Whisper] æ¨¡å‹æœªåˆå§‹åŒ–")
            return None, None, 0.0
        
        t0 = time.time()
        try:
            segments, info = self.model.transcribe(
                audio_data,
                beam_size=1,
                best_of=1,
                temperature=0,
                language=language,
                initial_prompt=prompt,
                vad_filter=False,
                vad_parameters=dict(
                    threshold=0.3,
                    min_silence_duration_ms=500,
                    speech_pad_ms=400
                ),
                condition_on_previous_text=False
            )
            text = " ".join([s.text.strip() for s in segments])
            cost = time.time() - t0
            
            if text:
                logger.info(f"ğŸ‘‚ [Whisper] åŸæ–‡ [{info.language}][{cost:.2f}s]: {text}")
                return text, info.language, cost
            return None, None, cost
        except Exception as e:
            logger.error(f"âŒ [Whisper] æ¨ç†é”™è¯¯: {e}")
            return None, None, time.time() - t0
    
    def is_available(self) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨"""
        return self.model is not None
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.model = None

