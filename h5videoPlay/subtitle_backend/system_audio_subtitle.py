#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç³»ç»ŸéŸ³é¢‘å®æ—¶å­—å¹•æœåŠ¡
æ•´åˆUIã€éŸ³é¢‘é‡‡é›†ã€è¯­éŸ³è½¬æ–‡å­—ã€ç¿»è¯‘ç­‰æ¨¡å—
"""
import logging
import threading
import time
import numpy as np

# å¯¼å…¥å„ä¸ªæ¨¡å—
from ui.floating_window import FloatingWindow
from audio.audio_capture import AudioCapture
from stt_service import STTService
from translation.translator import Translator

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class SystemAudioSubtitleService:
    """ç³»ç»ŸéŸ³é¢‘å®æ—¶å­—å¹•æœåŠ¡"""
    
    def __init__(self, model_size="small", device="cpu", target_lang="zh-CN", source_lang=None, 
                 sample_rate=16000, chunk_duration=2.0, config_file="model_config.json",
                 min_rms_for_stt: float = 3e-3):
        """
        åˆå§‹åŒ–æœåŠ¡
        
        Args:
            model_size: æ¨¡å‹å¤§å°ï¼ˆä¿ç•™å…¼å®¹æ€§ï¼Œå®é™…ä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰
            device: è®¾å¤‡ï¼ˆä¿ç•™å…¼å®¹æ€§ï¼Œå®é™…ä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰
            target_lang: ç›®æ ‡è¯­è¨€ï¼Œé»˜è®¤"zh-CN"
            source_lang: æºè¯­è¨€ï¼ŒNoneè¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹
            sample_rate: é‡‡æ ·ç‡ï¼Œé»˜è®¤16000Hz
            chunk_duration: éŸ³é¢‘å—æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤2.0ç§’
            config_file: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.target_lang = target_lang
        self.source_lang = source_lang
        self.sample_rate = sample_rate
        self.chunk_duration = chunk_duration
        # é¢å¤–çš„æ•´ä½“èƒ½é‡é—¨é™ï¼Œç”¨äºåœ¨è¿›å…¥å¤§æ¨¡å‹å‰å†è¿‡æ»¤ä¸€å±‚é™éŸ³ / ç¯å¢ƒå™ªå£°
        self.min_rms_for_stt = min_rms_for_stt
        
        # åˆå§‹åŒ–å„ä¸ªæ¨¡å—
        self.stt_service = STTService(config_file)
        self.translator = Translator(target_lang=target_lang)
        self.audio_capture = AudioCapture(sample_rate=sample_rate, chunk_duration=chunk_duration)
        
        # UIå’Œçº¿ç¨‹æ§åˆ¶
        self.floating_window = None
        self.process_thread = None
        self.is_recording = False
        
        # éŸ³é¢‘å¤„ç†ç›¸å…³
        self.prev_audio = np.array([], dtype=np.float32)
        self.sentence_buffer = ""
        self.last_speech_time = time.time()
    
    def initialize(self):
        """åˆå§‹åŒ–æœåŠ¡"""
        # åˆå§‹åŒ–è¯­éŸ³è½¬æ–‡å­—æœåŠ¡
        if not self.stt_service.initialize():
            raise RuntimeError("è¯­éŸ³è½¬æ–‡å­—æœåŠ¡åˆå§‹åŒ–å¤±è´¥")
        
        logger.info("âœ… æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
    
    def switch_model(self, model_name: str) -> bool:
        """
        åˆ‡æ¢æ¨¡å‹
        
        Args:
            model_name: æ¨¡å‹åç§°
            
        Returns:
            æ˜¯å¦åˆ‡æ¢æˆåŠŸ
        """
        return self.stt_service.switch_model(model_name)
    
    def update_translator(self, new_lang: str):
        """
        æ›´æ–°ç¿»è¯‘å™¨ç›®æ ‡è¯­è¨€
        
        Args:
            new_lang: æ–°çš„ç›®æ ‡è¯­è¨€ä»£ç 
        """
        self.target_lang = new_lang
        self.translator.update_target_lang(new_lang)
    
    def update_source_lang(self, new_lang: str):
        """
        æ›´æ–°æºè¯­è¨€
        
        Args:
            new_lang: æ–°çš„æºè¯­è¨€ä»£ç ï¼Œ"Auto"è¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹
        """
        # "Auto" è½¬ä¸º Noneï¼Œå…¶ä»–ä¿æŒåŸæ ·
        lang_code = None if new_lang == "Auto" else new_lang
        logger.info(f"ğŸ¤ åˆ‡æ¢æºè¯­è¨€: {new_lang} -> {lang_code}")
        self.source_lang = lang_code
        self.translator.update_source_lang(new_lang)
    
    def _is_same_language(self, detected_lang: str, target_lang: str) -> bool:
        """
        åˆ¤æ–­æ£€æµ‹åˆ°çš„è¯­è¨€å’Œç›®æ ‡è¯­è¨€æ˜¯å¦ç›¸åŒ
        
        Args:
            detected_lang: æ£€æµ‹åˆ°çš„è¯­è¨€ä»£ç 
            target_lang: ç›®æ ‡è¯­è¨€ä»£ç 
            
        Returns:
            æ˜¯å¦ç›¸åŒ
        """
        if not detected_lang or not target_lang:
            return False
        # å–æ¨ªæ å‰çš„éƒ¨åˆ†è¿›è¡Œå¯¹æ¯”: zh-CN -> zh
        d_code = detected_lang.lower().split('-')[0]
        t_code = target_lang.lower().split('-')[0]
        return d_code == t_code
    
    def _is_cjk(self, text: str) -> bool:
        """åˆ¤æ–­æ–‡æœ¬æ˜¯å¦åŒ…å«ä¸­æ—¥éŸ©å­—ç¬¦"""
        if not text:
            return False
        return any(u'\u4e00' <= char <= u'\u9fff' for char in text)
    
    def _process_loop(self):
        """éŸ³é¢‘å¤„ç†å¾ªç¯"""
        audio_buffer = []
        curr_samples = 0
        overlap_samples = int(self.sample_rate * 0.5)
        
        while self.is_recording:
            try:
                # æ£€æŸ¥é˜Ÿåˆ—ç§¯å‹
                if self.audio_capture.get_queue_size() > 6:
                    logger.warning("âš¡ ä¸¢å¼ƒç§¯å‹æ•°æ®...")
                    self.audio_capture.clear_queue()
                    audio_buffer = []
                    curr_samples = 0
                    self.sentence_buffer = ""
                    continue

                # è·å–éŸ³é¢‘å—
                chunk = self.audio_capture.get_chunk(timeout=0.5)
                if chunk is None:
                    # è¶…æ—¶ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦å¤„ç†ç¼“å†²åŒºä¸­çš„æ–‡æœ¬
                    if time.time() - self.last_speech_time > 3.0 and self.sentence_buffer:
                        self._translate_worker(self.sentence_buffer, 0.0, final=True)
                        self.sentence_buffer = ""
                    continue

                audio_buffer.append(chunk)
                curr_samples += len(chunk)

                # å½“ç§¯ç´¯è¶³å¤Ÿçš„éŸ³é¢‘æ—¶è¿›è¡Œå¤„ç†
                if curr_samples >= self.audio_capture.chunk_samples:
                    # æ‹¼æ¥éŸ³é¢‘
                    raw_audio = np.concatenate(audio_buffer, axis=0).flatten().astype(np.float32)
                    if len(self.prev_audio) > 0:
                        proc_audio = np.concatenate((self.prev_audio, raw_audio))
                    else:
                        proc_audio = raw_audio
                    
                    # ä¿å­˜é‡å éƒ¨åˆ†ç”¨äºä¸‹æ¬¡å¤„ç†
                    self.prev_audio = raw_audio[-overlap_samples:]
                    
                    # ===== é¢å¤–çš„é™éŸ³è¿‡æ»¤ï¼ˆæ•´ä½“èƒ½é‡é—¨ï¼‰ =====
                    try:
                        rms = float(np.sqrt(np.mean(proc_audio * proc_audio)))
                    except Exception as e:
                        logger.warning(f"è®¡ç®—æ•´ä½“RMSå¤±è´¥ï¼Œä»ç„¶é€å…¥è¯†åˆ«: {e}")
                        rms = self.min_rms_for_stt

                    if rms < self.min_rms_for_stt:
                        # æ•´ä½“èƒ½é‡ä¹Ÿå¾ˆä½ï¼Œè®¤ä¸ºä¸»è¦æ˜¯ç¯å¢ƒåº•å™ª / é™éŸ³ï¼Œç›´æ¥è·³è¿‡è¯†åˆ«
                        logger.debug(f"è·³è¿‡é™éŸ³å—ï¼Œä¸é€å…¥è¯†åˆ« (rms={rms:.6f} < {self.min_rms_for_stt:.6f})")
                        audio_buffer = []
                        curr_samples = 0
                        continue
                    # ===== é¢å¤–é™éŸ³è¿‡æ»¤ç»“æŸ =====

                    # ä½¿ç”¨ä¸Šä¸€å¥çš„å50ä¸ªå­—ç¬¦ä½œä¸ºæç¤º
                    prompt = self.sentence_buffer[-50:] if self.sentence_buffer else ""
                    
                    # è¯­éŸ³è½¬æ–‡å­—
                    text, lang, cost = self.stt_service.transcribe(
                        proc_audio,
                        sample_rate=self.sample_rate,
                        language=self.source_lang,
                        prompt=prompt
                    )
                    
                    if text:
                        self.last_speech_time = time.time()
                        
                        # æ–‡æœ¬æ‹¼æ¥é€»è¾‘
                        if not self.sentence_buffer.endswith(text):
                            sep = " " if self.sentence_buffer and not self._is_cjk(text) else ""
                            self.sentence_buffer += sep + text
                        self.sentence_buffer = self.sentence_buffer.strip()
                        
                        # å…ˆåœ¨åŸæ–‡åŒºåŸŸæ˜¾ç¤ºï¼ˆå¸¦çœç•¥å·è¡¨ç¤ºæœªå®Œï¼‰
                        if self.floating_window:
                            self.floating_window.update_text(self.sentence_buffer, "...", {'rec': cost})
                        
                        # åˆ¤æ–­æ˜¯å¦éœ€è¦ç¿»è¯‘
                        if not self._is_same_language(lang, self.target_lang):
                            self._translate_worker(self.sentence_buffer, cost, final=False)
                        else:
                            # åŒè¯­è¨€ï¼šè¯‘æ–‡åŒºç›´æ¥æ˜¾ç¤ºåŸæ–‡
                            logger.info(f"â­ï¸ åŒè¯­è¨€ [{lang}=={self.target_lang}]ï¼Œè·³è¿‡ç¿»è¯‘")
                            if self.floating_window:
                                self.floating_window.update_text(
                                    self.sentence_buffer, 
                                    self.sentence_buffer, 
                                    {'rec': cost}
                                )
                    
                    # æ¸…ç©ºç¼“å†²åŒº
                    audio_buffer = []
                    curr_samples = 0
                    
            except Exception as e:
                logger.error(f"å¤„ç†éŸ³é¢‘æ—¶å‡ºé”™: {e}", exc_info=True)
    
    def _translate_worker(self, text: str, rec_cost: float = 0.0, final: bool = False):
        """
        ç¿»è¯‘å·¥ä½œçº¿ç¨‹
        
        Args:
            text: è¦ç¿»è¯‘çš„æ–‡æœ¬
            rec_cost: è¯†åˆ«è€—æ—¶
            final: æ˜¯å¦ä¸ºæœ€ç»ˆç¿»è¯‘
        """
        def on_translate_complete(translated_text: str, trans_cost: float):
            """ç¿»è¯‘å®Œæˆå›è°ƒ"""
            if self.floating_window:
                self.floating_window.update_text(
                    text, 
                    translated_text or text, 
                    {'rec': rec_cost, 'trans': trans_cost}
                )
        
        self.translator.translate_async(text, on_translate_complete, rec_cost)
    
    def start(self):
        """å¯åŠ¨æœåŠ¡"""
        # åˆå§‹åŒ–æœåŠ¡
        self.initialize()
        
        # åˆ›å»ºUIçª—å£
        initial_source_ui = self.source_lang if self.source_lang else "Auto"
        available_models = self.stt_service.get_available_models()
        current_model = self.stt_service.get_current_model()
        
        self.floating_window = FloatingWindow(
            target_lang=self.target_lang,
            source_lang=initial_source_ui,
            lang_callback=self.update_translator,
            source_lang_callback=self.update_source_lang,
            model_callback=self.switch_model,
            available_models=available_models,
            current_model=current_model or "whisper"
        )
        self.floating_window.create_window()
        
        # å¯åŠ¨éŸ³é¢‘é‡‡é›†
        if not self.audio_capture.start():
            logger.error("éŸ³é¢‘é‡‡é›†å¯åŠ¨å¤±è´¥")
            return
        
        # å¯åŠ¨å¤„ç†çº¿ç¨‹
        self.is_recording = True
        self.process_thread = threading.Thread(target=self._process_loop, daemon=True)
        self.process_thread.start()
        
        # ä¿æŒä¸»çº¿ç¨‹è¿è¡Œ
        def keep_alive():
            if not self.is_recording:
                if self.process_thread and not self.process_thread.is_alive():
                    if self.floating_window and self.floating_window.root:
                        self.floating_window.root.quit()
            else:
                if self.floating_window and self.floating_window.root:
                    self.floating_window.root.after(1000, keep_alive)
        
        keep_alive()
        
        try:
            if self.floating_window and self.floating_window.root:
                self.floating_window.root.mainloop()
        except KeyboardInterrupt:
            logger.info("æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨å…³é—­...")
        except Exception as e:
            logger.error(f"è¿è¡Œå‡ºé”™: {e}", exc_info=True)
        finally:
            self.stop()
    
    def stop(self):
        """åœæ­¢æœåŠ¡"""
        logger.info("æ­£åœ¨åœæ­¢æœåŠ¡...")
        self.is_recording = False
        
        # åœæ­¢éŸ³é¢‘é‡‡é›†
        self.audio_capture.stop()
        
        # æ¸…ç†èµ„æº
        self.stt_service.cleanup()
        
        # å…³é—­UI
        if self.floating_window:
            self.floating_window.close_window()
        
        logger.info("æœåŠ¡å·²åœæ­¢")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    parser = argparse.ArgumentParser(description="ç³»ç»ŸéŸ³é¢‘å®æ—¶å­—å¹•æœåŠ¡")
    parser.add_argument("--model", type=str, default="auto", help="æ¨¡å‹å¤§å°ï¼ˆå·²åºŸå¼ƒï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶ï¼‰")
    parser.add_argument("--device", type=str, default="cpu", help="è®¾å¤‡ï¼ˆå·²åºŸå¼ƒï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶ï¼‰")
    parser.add_argument("--source-lang", type=str, default=None, help="æºè¯­è¨€")
    parser.add_argument("--target-lang", type=str, default="zh-CN", help="ç›®æ ‡è¯­è¨€")
    parser.add_argument("--chunk-duration", type=float, default=2.0, help="éŸ³é¢‘å—æ—¶é•¿ï¼ˆç§’ï¼‰")
    parser.add_argument("--config", type=str, default="model_config.json", help="é…ç½®æ–‡ä»¶è·¯å¾„")
    
    args = parser.parse_args()
    
    service = SystemAudioSubtitleService(
        model_size=args.model,
        device=args.device,
        target_lang=args.target_lang,
        source_lang=args.source_lang,
        chunk_duration=args.chunk_duration,
        config_file=args.config
    )
    
    try:
        service.start()
    except KeyboardInterrupt:
        logger.info("ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"ç¨‹åºè¿è¡Œå‡ºé”™: {e}", exc_info=True)
    finally:
        service.stop()


if __name__ == "__main__":
    main()
