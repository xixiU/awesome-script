#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç³»ç»ŸéŸ³é¢‘å®æ—¶å­—å¹•æœåŠ¡
æ•´åˆUIã€éŸ³é¢‘é‡‡é›†ã€è¯­éŸ³è½¬æ–‡å­—ã€ç¿»è¯‘ç­‰æ¨¡å—
"""
import logging
import threading
import time
import queue
import numpy as np
import multiprocessing
import sys

# å¯¼å…¥å„ä¸ªæ¨¡å—
from ui.floating_window import FloatingWindow
from audio.audio_capture import AudioCapture
from stt_service import STTService
from translation.translator import Translator

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class SystemAudioSubtitleService:
    """ç³»ç»ŸéŸ³é¢‘å®æ—¶å­—å¹•æœåŠ¡"""
    
    def __init__(self, model_size="small", target_lang="zh-CN", source_lang=None, 
                 sample_rate=16000, chunk_duration=2.0, config_file="model_config.json",
                 min_rms_for_stt: float = 1e-3,
                 silence_duration_for_sentence_end: float = 1.5,
                 max_sentence_duration: float = 10.0):
        """
        åˆå§‹åŒ–æœåŠ¡
        
        Args:
            model_size: æ¨¡å‹å¤§å°ï¼ˆä¿ç•™å…¼å®¹æ€§ï¼Œå®é™…ä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰
            target_lang: ç›®æ ‡è¯­è¨€ï¼Œé»˜è®¤"zh-CN"
            source_lang: æºè¯­è¨€ï¼ŒNoneè¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹
            sample_rate: é‡‡æ ·ç‡ï¼Œé»˜è®¤16000Hz
            chunk_duration: éŸ³é¢‘å—æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤2.0ç§’ï¼ˆç”¨äºè¯†åˆ«ï¼Œä½†ä¼šç´¯ç§¯å¥å­ï¼‰
            config_file: é…ç½®æ–‡ä»¶è·¯å¾„
            min_rms_for_stt: é€å…¥è¯†åˆ«çš„æœ€å°RMSé˜ˆå€¼
            silence_duration_for_sentence_end: é™éŸ³æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œè¶…è¿‡æ­¤å€¼è®¤ä¸ºå¥å­ç»“æŸ
            max_sentence_duration: æœ€å¤§å¥å­æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œè¶…è¿‡æ­¤å€¼å¼ºåˆ¶è¾“å‡º
        """
        self.target_lang = target_lang
        self.source_lang = source_lang
        self.sample_rate = sample_rate
        self.chunk_duration = chunk_duration
        # é¢å¤–çš„æ•´ä½“èƒ½é‡é—¨é™ï¼Œç”¨äºåœ¨è¿›å…¥å¤§æ¨¡å‹å‰å†è¿‡æ»¤ä¸€å±‚é™éŸ³ / ç¯å¢ƒå™ªå£°
        self.min_rms_for_stt = min_rms_for_stt
        self.silence_duration_for_sentence_end = silence_duration_for_sentence_end
        self.max_sentence_duration = max_sentence_duration
        
        # æ—¥å¿—é™æµè®¡æ•°å™¨
        self.log_counter = 0
        
        # åˆå§‹åŒ–å„ä¸ªæ¨¡å—
        self.stt_service = STTService(config_file)
        self.translator = Translator(target_lang=target_lang)
        # ä½¿ç”¨è¾ƒçŸ­çš„chunk_durationè¿›è¡Œå¿«é€Ÿè¯†åˆ«ï¼Œä½†ä¼šç´¯ç§¯æˆå®Œæ•´å¥å­
        self.audio_capture = AudioCapture(sample_rate=sample_rate, chunk_duration=chunk_duration)
        
        # çº¿ç¨‹æ§åˆ¶
        self.floating_window = None
        self.capture_thread = None
        self.process_thread = None
        self.is_recording = False
        
        # çº¿ç¨‹å®‰å…¨çš„æ•°æ®é˜Ÿåˆ—
        self.data_queue = queue.Queue()
        
        # éŸ³é¢‘å¤„ç†ç›¸å…³
        self.prev_audio = np.array([], dtype=np.float32)
        self.sentence_buffer = ""  # ç´¯ç§¯çš„å®Œæ•´å¥å­
        self.last_speech_time = time.time()
        self.last_silence_start_time = None  # é™éŸ³å¼€å§‹æ—¶é—´
        self.sentence_start_time = None  # å½“å‰å¥å­å¼€å§‹æ—¶é—´
        self.is_in_sentence = False  # æ˜¯å¦æ­£åœ¨æ„å»ºå¥å­
        self.pending_translation = None  # å¾…ç¿»è¯‘çš„å¥å­ï¼ˆé¿å…é‡å¤ç¿»è¯‘ï¼‰
        self.last_detected_lang = None  # æœ€åä¸€æ¬¡æ£€æµ‹åˆ°çš„è¯­è¨€
        self.current_translation_task_id = 0  # å½“å‰ç¿»è¯‘ä»»åŠ¡IDï¼Œç”¨äºå–æ¶ˆæ—§ä»»åŠ¡
        self.last_translated_text = ""  # æœ€åä¸€æ¬¡ç¿»è¯‘çš„æ–‡æœ¬
    
    def initialize(self):
        """åˆå§‹åŒ–æœåŠ¡"""
        # åˆå§‹åŒ–è¯­éŸ³è½¬æ–‡å­—æœåŠ¡
        if not self.stt_service.initialize():
            raise RuntimeError("è¯­éŸ³è½¬æ–‡å­—æœåŠ¡åˆå§‹åŒ–å¤±è´¥")
        
        logger.info("âœ… æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
    
    def switch_model(self, model_name: str) -> bool:
        """
        åˆ‡æ¢æ¨¡å‹
        
        Args:
            model_name: æ¨¡å‹åç§°
            
        Returns:
            æ˜¯å¦åˆ‡æ¢æˆåŠŸ
        """
        return self.stt_service.switch_model(model_name)
    
    def update_translator(self, new_lang: str):
        """
        æ›´æ–°ç¿»è¯‘å™¨ç›®æ ‡è¯­è¨€
        
        Args:
            new_lang: æ–°çš„ç›®æ ‡è¯­è¨€ä»£ç 
        """
        self.target_lang = new_lang
        self.translator.update_target_lang(new_lang)
    
    def update_source_lang(self, new_lang: str):
        """
        æ›´æ–°æºè¯­è¨€
        
        Args:
            new_lang: æ–°çš„æºè¯­è¨€ä»£ç ï¼Œ"Auto"è¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹
        """
        # "Auto" è½¬ä¸º Noneï¼Œå…¶ä»–ä¿æŒåŸæ ·
        lang_code = None if new_lang == "Auto" else new_lang
        logger.info(f"ğŸ¤ åˆ‡æ¢æºè¯­è¨€: {new_lang} -> {lang_code}")
        self.source_lang = lang_code
        self.translator.update_source_lang(new_lang)
    
    def _is_same_language(self, detected_lang: str, target_lang: str) -> bool:
        """
        åˆ¤æ–­æ£€æµ‹åˆ°çš„è¯­è¨€å’Œç›®æ ‡è¯­è¨€æ˜¯å¦ç›¸åŒ
        
        Args:
            detected_lang: æ£€æµ‹åˆ°çš„è¯­è¨€ä»£ç 
            target_lang: ç›®æ ‡è¯­è¨€ä»£ç 
            
        Returns:
            æ˜¯å¦ç›¸åŒ
        """
        if not detected_lang or not target_lang:
            return False
        # å–æ¨ªæ å‰çš„éƒ¨åˆ†è¿›è¡Œå¯¹æ¯”: zh-CN -> zh
        d_code = detected_lang.lower().split('-')[0]
        t_code = target_lang.lower().split('-')[0]
        return d_code == t_code
    
    def _is_cjk(self, text: str) -> bool:
        """åˆ¤æ–­æ–‡æœ¬æ˜¯å¦åŒ…å«ä¸­æ—¥éŸ©å­—ç¬¦"""
        if not text:
            return False
        return any(u'\u4e00' <= char <= u'\u9fff' for char in text)
    
    def _capture_loop(self):
        """
        éŸ³é¢‘é‡‡é›†çº¿ç¨‹
        åªè´Ÿè´£ä»è®¾å¤‡é‡‡é›†éŸ³é¢‘å¹¶æ”¾å…¥é˜Ÿåˆ—ï¼Œä¸åšè€—æ—¶å¤„ç†
        """
        while self.is_recording:
            try:
                # ä»éŸ³é¢‘è®¾å¤‡è·å–æ•°æ®
                chunk = self.audio_capture.get_chunk(timeout=0.5)
                if chunk is not None:
                    # ç›‘æ§é˜Ÿåˆ—é•¿åº¦
                    qsize = self.data_queue.qsize()
                    # è®¡ç®—æ­£å¸¸çš„ç´¯ç§¯é‡ï¼šchunk_duration (2s) / 0.1s = 20å—
                    # åªæœ‰è¿œè¶…æ­£å¸¸ç´¯ç§¯é‡æ‰è­¦å‘Š
                    normal_buffer_size = int(self.chunk_duration / 0.1)
                    warning_threshold = max(30, normal_buffer_size * 2)
                    drop_threshold = max(100, normal_buffer_size * 5)

                    if qsize > drop_threshold:
                        # ç§¯å‹ä¸¥é‡ï¼Œä¸¢å¼ƒæ•°æ®é˜²æ­¢å†…å­˜æº¢å‡º
                        if self.log_counter % 10 == 0:
                            logger.warning(f"âš¡ é˜Ÿåˆ—ç§¯å‹ä¸¥é‡ ({qsize}å—)ï¼Œä¸¢å¼ƒå½“å‰å¸§...")
                        self.log_counter += 1
                        
                        # å°è¯•æ¸…ç©ºä¸€éƒ¨åˆ†æ—§æ•°æ®
                        try:
                            for _ in range(10):
                                self.data_queue.get_nowait()
                        except queue.Empty:
                            pass
                    elif qsize > warning_threshold:
                        # ç§¯å‹è­¦å‘Šï¼Œä½†ä¸ä¸¢å¼ƒï¼ˆé™åˆ¶æ‰“å°é¢‘ç‡ï¼Œæ¯10æ¬¡/1ç§’æ‰“å°ä¸€æ¬¡ï¼‰
                        if self.log_counter % 10 == 0:
                            logger.warning(f"âš ï¸ é˜Ÿåˆ—ç§¯å‹è­¦å‘Š: {qsize}å—å¾…å¤„ç†")
                        self.log_counter += 1
                    else:
                        # æ­£å¸¸çŠ¶æ€é‡ç½®è®¡æ•°å™¨ï¼ˆå¯é€‰ï¼Œä¸ºäº†ä¿æŒè®¡æ•°è¿ç»­æ€§ä¹Ÿå¯ä»¥ä¸é‡ç½®ï¼‰
                        pass
                    
                    # æ”¾å…¥å†…éƒ¨æ•°æ®é˜Ÿåˆ—
                    self.data_queue.put(chunk)
            except Exception as e:
                logger.error(f"é‡‡é›†çº¿ç¨‹å‡ºé”™: {e}")
                time.sleep(0.1)

    def _process_loop(self):
        """
        éŸ³é¢‘å¤„ç†çº¿ç¨‹
        è´Ÿè´£ä»é˜Ÿåˆ—å–å‡ºæ•°æ®è¿›è¡Œè¯†åˆ«å’Œç¿»è¯‘
        """
        audio_buffer = []
        curr_samples = 0
        overlap_samples = int(self.sample_rate * 0.5)
        current_time = time.time()
        
        while self.is_recording:
            try:
                # ä»é˜Ÿåˆ—è·å–éŸ³é¢‘æ•°æ®ï¼ˆéé˜»å¡ï¼Œæˆ–è€…çŸ­è¶…æ—¶ï¼‰
                try:
                    # ä¸€æ¬¡æ€§å–å‡ºé˜Ÿåˆ—ä¸­æ‰€æœ‰ç§¯å‹çš„æ•°æ®ï¼Œé˜²æ­¢å¤„ç†é€Ÿåº¦è·Ÿä¸ä¸Š
                    chunks = []
                    while not self.data_queue.empty():
                        chunks.append(self.data_queue.get_nowait())
                    
                    # å¦‚æœé˜Ÿåˆ—ä¸ºç©ºï¼Œå°è¯•ç­‰å¾…ä¸€å°ä¼šå„¿
                    if not chunks:
                        chunk = self.data_queue.get(timeout=0.1)
                        chunks.append(chunk)
                except queue.Empty:
                    # è¶…æ—¶ï¼Œæ£€æŸ¥å¥å­æ˜¯å¦åº”è¯¥ç»“æŸ
                    current_time = time.time()
                    self._check_sentence_end(current_time, force_check=True)
                    continue

                # ç›‘æ§å¤„ç†å»¶è¿Ÿ
                process_start_time = time.time()
                queue_wait_time = process_start_time - current_time if current_time > 0 else 0
                if queue_wait_time > 1.0:
                    logger.info(f"ğŸ•’ å¤„ç†å»¶è¿Ÿ: {queue_wait_time:.2f}s")

                current_time = process_start_time
                
                # å°†æ‰€æœ‰æ–°è·å–çš„å—åŠ å…¥ç¼“å†²åŒº
                if len(chunks) > 10:
                    logger.info(f"ğŸš€ æ­£åœ¨åˆå¹¶å¤„ç† {len(chunks)} ä¸ªç§¯å‹éŸ³é¢‘å— (çº¦ {len(chunks)*0.1:.1f}ç§’)...")
                
                for chunk in chunks:
                    audio_buffer.append(chunk)
                    curr_samples += len(chunk)

                # å½“ç§¯ç´¯è¶³å¤Ÿçš„éŸ³é¢‘æ—¶è¿›è¡Œå¤„ç†
                if curr_samples >= self.audio_capture.chunk_samples:
                    # æ‹¼æ¥éŸ³é¢‘
                    raw_audio = np.concatenate(audio_buffer, axis=0).flatten().astype(np.float32)
                    if len(self.prev_audio) > 0:
                        proc_audio = np.concatenate((self.prev_audio, raw_audio))
                    else:
                        proc_audio = raw_audio
                    
                    # ä¿å­˜é‡å éƒ¨åˆ†ç”¨äºä¸‹æ¬¡å¤„ç†
                    self.prev_audio = raw_audio[-overlap_samples:]
                    
                    # ===== é¢å¤–çš„é™éŸ³è¿‡æ»¤ï¼ˆæ•´ä½“èƒ½é‡é—¨ï¼‰ =====
                    try:
                        rms = float(np.sqrt(np.mean(proc_audio * proc_audio)))
                    except Exception as e:
                        logger.warning(f"è®¡ç®—æ•´ä½“RMSå¤±è´¥ï¼Œä»ç„¶é€å…¥è¯†åˆ«: {e}")
                        rms = self.min_rms_for_stt

                    is_silence = rms < self.min_rms_for_stt
                    
                    # ç§¯å‹å¤„ç†ç­–ç•¥ï¼šå¦‚æœç§¯å‹ä¸¥é‡ï¼Œä¸”å½“å‰æ˜¯é™éŸ³ï¼Œåˆ™æ›´æ¿€è¿›åœ°ä¸¢å¼ƒ
                    qsize = self.data_queue.qsize()
                    if qsize > 5 and is_silence:
                        # ç§¯å‹ä¸­ï¼Œä¸”å½“å‰æ˜¯é™éŸ³ï¼Œç›´æ¥è·³è¿‡ï¼Œä¸è®¡å…¥é™éŸ³æ—¶é•¿ï¼ŒåŠ é€Ÿè¿½èµ¶
                        logger.debug(f"ç§¯å‹è¿½èµ¶ï¼šè·³è¿‡é™éŸ³å— (qsize={qsize})")
                        audio_buffer = []
                        curr_samples = 0
                        continue

                    if is_silence:
                        # æ•´ä½“èƒ½é‡å¾ˆä½ï¼Œè®¤ä¸ºæ˜¯é™éŸ³
                        logger.debug(f"è·³è¿‡é™éŸ³å—ï¼Œä¸é€å…¥è¯†åˆ« (rms={rms:.6f} < {self.min_rms_for_stt:.6f})")
                        
                        # å¦‚æœæ­£åœ¨æ„å»ºå¥å­ï¼Œè®°å½•é™éŸ³å¼€å§‹æ—¶é—´
                        if self.is_in_sentence:
                            if self.last_silence_start_time is None:
                                self.last_silence_start_time = current_time
                            # æ£€æŸ¥æ˜¯å¦åº”è¯¥ç»“æŸå¥å­
                            self._check_sentence_end(current_time)
                        
                        audio_buffer = []
                        curr_samples = 0
                        continue
                    # ===== é¢å¤–é™éŸ³è¿‡æ»¤ç»“æŸ =====
                    
                    # æ£€æµ‹åˆ°æœ‰æ•ˆéŸ³é¢‘ï¼Œé‡ç½®é™éŸ³è®¡æ—¶
                    if self.last_silence_start_time is not None:
                        self.last_silence_start_time = None
                    
                    # å¦‚æœè¿™æ˜¯æ–°å¥å­çš„å¼€å§‹
                    if not self.is_in_sentence:
                        self.is_in_sentence = True
                        self.sentence_start_time = current_time
                        self.sentence_buffer = ""
                        logger.debug("ğŸ¤ å¼€å§‹æ–°å¥å­")

                    # ä½¿ç”¨ä¸Šä¸€å¥çš„å50ä¸ªå­—ç¬¦ä½œä¸ºæç¤º
                    prompt = self.sentence_buffer[-50:] if self.sentence_buffer else ""
                    
                    # è¯­éŸ³è½¬æ–‡å­—
                    text, lang, cost = self.stt_service.transcribe(
                        proc_audio,
                        sample_rate=self.sample_rate,
                        language=self.source_lang,
                        prompt=prompt
                    )
                    
                    if text:
                        self.last_speech_time = current_time
                        self.last_detected_lang = lang  # ä¿å­˜æ£€æµ‹åˆ°çš„è¯­è¨€
                        
                        # æ–‡æœ¬æ‹¼æ¥é€»è¾‘
                        if not self.sentence_buffer.endswith(text):
                            sep = " " if self.sentence_buffer and not self._is_cjk(text) else ""
                            self.sentence_buffer += sep + text
                        self.sentence_buffer = self.sentence_buffer.strip()
                        
                        # å®æ—¶é¢„è§ˆï¼šæ˜¾ç¤ºå½“å‰ç´¯ç§¯çš„å¥å­ï¼ˆå¸¦çœç•¥å·è¡¨ç¤ºæœªå®Œï¼‰
                        current_sentence = self.sentence_buffer + "..."
                        if self.floating_window:
                            # ä¼  None ç»™ç¿»è¯‘éƒ¨åˆ†ï¼Œä¿æŒä¸Šä¸€å¥ç¿»è¯‘æˆ–ç­‰å¾…å®æ—¶ç¿»è¯‘
                            self.floating_window.update_text(current_sentence, None, {'rec': cost})
                        
                        # å®æ—¶ç¿»è¯‘ï¼šç«‹å³ç¿»è¯‘å½“å‰ç´¯ç§¯çš„å¥å­ï¼ˆé¢„è§ˆï¼‰
                        self._translate_realtime(current_sentence, cost)
                        
                        # æ£€æŸ¥å¥å­æ˜¯å¦åº”è¯¥ç»“æŸï¼ˆåŸºäºæœ€å¤§æ—¶é•¿ï¼‰
                        self._check_sentence_end(current_time)
                    
                    # æ¸…ç©ºç¼“å†²åŒº
                    audio_buffer = []
                    curr_samples = 0
                    
            except Exception as e:
                logger.error(f"å¤„ç†éŸ³é¢‘æ—¶å‡ºé”™: {e}", exc_info=True)
    
    def _check_sentence_end(self, current_time: float, force_check: bool = False):
        """
        æ£€æŸ¥å¥å­æ˜¯å¦åº”è¯¥ç»“æŸ
        
        Args:
            current_time: å½“å‰æ—¶é—´
            force_check: æ˜¯å¦å¼ºåˆ¶æ£€æŸ¥ï¼ˆå³ä½¿æ²¡æœ‰é™éŸ³ï¼‰
        """
        if not self.is_in_sentence or not self.sentence_buffer:
            return
        
        should_end = False
        reason = ""
        
        # æƒ…å†µ1: æ£€æµ‹åˆ°è¶³å¤Ÿé•¿çš„é™éŸ³
        if self.last_silence_start_time is not None:
            silence_duration = current_time - self.last_silence_start_time
            if silence_duration >= self.silence_duration_for_sentence_end:
                should_end = True
                reason = f"é™éŸ³æŒç»­ {silence_duration:.2f}ç§’"
        
        # æƒ…å†µ2: å¥å­æŒç»­æ—¶é—´è¿‡é•¿ï¼ˆå¼ºåˆ¶è¾“å‡ºï¼Œé¿å…å»¶è¿Ÿï¼‰
        if self.sentence_start_time is not None:
            sentence_duration = current_time - self.sentence_start_time
            if sentence_duration >= self.max_sentence_duration:
                should_end = True
                reason = f"å¥å­æŒç»­ {sentence_duration:.2f}ç§’ï¼ˆè¶…æ—¶ï¼‰"
        
        # æƒ…å†µ3: å¼ºåˆ¶æ£€æŸ¥ä¸”è·ç¦»ä¸Šæ¬¡è¯­éŸ³æ—¶é—´è¿‡é•¿
        if force_check and (current_time - self.last_speech_time) > 3.0:
            should_end = True
            reason = "é•¿æ—¶é—´æ— è¯­éŸ³"
        
        if should_end:
            logger.info(f"ğŸ“ å¥å­ç»“æŸ: {reason}")
            self._finalize_sentence()
    
    def _translate_realtime(self, text: str, rec_cost: float = 0.0):
        """
        å®æ—¶ç¿»è¯‘é¢„è§ˆï¼ˆå¥å­æ„å»ºè¿‡ç¨‹ä¸­ï¼‰
        
        Args:
            text: å½“å‰ç´¯ç§¯çš„æ–‡æœ¬ï¼ˆå¯èƒ½å¸¦çœç•¥å·ï¼‰
            rec_cost: è¯†åˆ«è€—æ—¶
        """
        # ä½¿ç”¨æœ€åä¸€æ¬¡æ£€æµ‹åˆ°çš„è¯­è¨€
        detected_lang = self.last_detected_lang
        
        # åˆ¤æ–­æ˜¯å¦éœ€è¦ç¿»è¯‘
        if detected_lang and not self._is_same_language(detected_lang, self.target_lang):
            # ç”Ÿæˆæ–°çš„ç¿»è¯‘ä»»åŠ¡ID
            self.current_translation_task_id += 1
            task_id = self.current_translation_task_id
            
            def on_translate_complete(translated_text: str, trans_cost: float):
                """ç¿»è¯‘å®Œæˆå›è°ƒ"""
                # åªå¤„ç†æœ€æ–°çš„ç¿»è¯‘ä»»åŠ¡ï¼Œå¿½ç•¥æ—§çš„
                if task_id == self.current_translation_task_id:
                    if self.floating_window:
                        # æ˜¾ç¤ºåŸæ–‡å’Œå®æ—¶ç¿»è¯‘é¢„è§ˆ
                        self.floating_window.update_text(
                            text, 
                            translated_text or text, 
                            {'rec': rec_cost, 'trans': trans_cost}
                        )
                    self.last_translated_text = translated_text or text
            
            # å¼‚æ­¥ç¿»è¯‘
            self.translator.translate_async(text, on_translate_complete, rec_cost)
        else:
            # åŒè¯­è¨€æˆ–è¯­è¨€æœªçŸ¥ï¼šç›´æ¥æ˜¾ç¤ºåŸæ–‡
            if self.floating_window:
                self.floating_window.update_text(text, text, {'rec': rec_cost})
    
    def _finalize_sentence(self):
        """å®Œæˆå½“å‰å¥å­ï¼Œæ˜¾ç¤ºå¹¶ç¿»è¯‘ï¼ˆæœ€ç»ˆçº æ­£ç‰ˆï¼‰"""
        if not self.sentence_buffer:
            self._reset_sentence_state()
            return
        
        final_text = self.sentence_buffer.strip()
        logger.info(f"âœ… å®Œæ•´å¥å­: {final_text}")
        
        # ä½¿ç”¨æœ€åä¸€æ¬¡æ£€æµ‹åˆ°çš„è¯­è¨€
        detected_lang = self.last_detected_lang
        
        # åˆ¤æ–­æ˜¯å¦éœ€è¦ç¿»è¯‘
        if detected_lang and not self._is_same_language(detected_lang, self.target_lang):
            # ç”Ÿæˆæ–°çš„ç¿»è¯‘ä»»åŠ¡IDï¼ˆæœ€ç»ˆç¿»è¯‘ä¼šè¦†ç›–å®æ—¶ç¿»è¯‘ï¼‰
            self.current_translation_task_id += 1
            task_id = self.current_translation_task_id
            
            def on_final_translate_complete(translated_text: str, trans_cost: float):
                """æœ€ç»ˆç¿»è¯‘å®Œæˆå›è°ƒ"""
                # åªå¤„ç†æœ€æ–°çš„ç¿»è¯‘ä»»åŠ¡
                if task_id == self.current_translation_task_id:
                    logger.info(f"ğŸŒ æœ€ç»ˆç¿»è¯‘: {translated_text}")
                    if self.floating_window:
                        # æ˜¾ç¤ºæœ€ç»ˆå®Œæ•´å¥å­å’Œæœ€ç»ˆç¿»è¯‘ï¼ˆè¦†ç›–ä¹‹å‰çš„é¢„è§ˆï¼‰
                        self.floating_window.update_text(
                            final_text, 
                            translated_text or final_text, 
                            {'trans': trans_cost}
                        )
                    self.last_translated_text = translated_text or final_text
            
            # å¼‚æ­¥ç¿»è¯‘å®Œæ•´å¥å­ï¼ˆæœ€ç»ˆç‰ˆæœ¬ï¼‰
            self.translator.translate_async(final_text, on_final_translate_complete, 0.0)
        else:
            # åŒè¯­è¨€æˆ–è¯­è¨€æœªçŸ¥ï¼šç›´æ¥æ˜¾ç¤ºå®Œæ•´å¥å­
            logger.info(f"â­ï¸ åŒè¯­è¨€æˆ–è¯­è¨€æœªçŸ¥ [{detected_lang}=={self.target_lang}]ï¼Œè·³è¿‡ç¿»è¯‘")
            if self.floating_window:
                self.floating_window.update_text(final_text, final_text, {})
        
        # é‡ç½®çŠ¶æ€
        self._reset_sentence_state()
    
    def _reset_sentence_state(self):
        """é‡ç½®å¥å­çŠ¶æ€"""
        self.sentence_buffer = ""
        self.is_in_sentence = False
        self.last_silence_start_time = None
        self.sentence_start_time = None
        self.pending_translation = None
        # æ³¨æ„ï¼šä¸é‡ç½® last_detected_lang å’Œ current_translation_task_id
        # å› ä¸ºä¸‹ä¸€å¥å¯èƒ½è¿˜æ˜¯åŒä¸€ç§è¯­è¨€ï¼Œä¸”ç¿»è¯‘ä»»åŠ¡IDç”¨äºåŒºåˆ†æ–°æ—§ä»»åŠ¡
    
    def start(self):
        """å¯åŠ¨æœåŠ¡"""
        # åˆå§‹åŒ–æœåŠ¡
        self.initialize()
        
        # åˆ›å»ºUIçª—å£
        initial_source_ui = self.source_lang if self.source_lang else "Auto"
        available_models = self.stt_service.get_available_models()
        current_model = self.stt_service.get_current_model()
        
        self.floating_window = FloatingWindow(
            target_lang=self.target_lang,
            source_lang=initial_source_ui,
            lang_callback=self.update_translator,
            source_lang_callback=self.update_source_lang,
            model_callback=self.switch_model,
            available_models=available_models,
            current_model=current_model or "whisper"
        )
        self.floating_window.create_window()
        
        # å¯åŠ¨éŸ³é¢‘é‡‡é›†
        if not self.audio_capture.start():
            logger.error("éŸ³é¢‘é‡‡é›†å¯åŠ¨å¤±è´¥")
            return
        
        # å¯åŠ¨å¤„ç†çº¿ç¨‹
        self.is_recording = True
        self.capture_thread = threading.Thread(target=self._capture_loop, daemon=True)
        self.process_thread = threading.Thread(target=self._process_loop, daemon=True)
        self.capture_thread.start()
        self.process_thread.start()
        
        # ä¿æŒä¸»çº¿ç¨‹è¿è¡Œ
        def keep_alive():
            if not self.is_recording:
                if self.process_thread and not self.process_thread.is_alive():
                    if self.floating_window and self.floating_window.root:
                        self.floating_window.root.quit()
            else:
                if self.floating_window and self.floating_window.root:
                    self.floating_window.root.after(1000, keep_alive)
        
        keep_alive()
        
        try:
            if self.floating_window and self.floating_window.root:
                self.floating_window.root.mainloop()
        except KeyboardInterrupt:
            logger.info("æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨å…³é—­...")
        except Exception as e:
            logger.error(f"è¿è¡Œå‡ºé”™: {e}", exc_info=True)
        finally:
            self.stop()
    
    def stop(self):
        """åœæ­¢æœåŠ¡"""
        logger.info("æ­£åœ¨åœæ­¢æœåŠ¡...")
        self.is_recording = False
        
        # åœæ­¢éŸ³é¢‘é‡‡é›†
        self.audio_capture.stop()
        
        # æ¸…ç†èµ„æº
        self.stt_service.cleanup()
        
        # å…³é—­UI
        if self.floating_window:
            self.floating_window.close_window()
        
        logger.info("æœåŠ¡å·²åœæ­¢")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    parser = argparse.ArgumentParser(description="ç³»ç»ŸéŸ³é¢‘å®æ—¶å­—å¹•æœåŠ¡")
    parser.add_argument("--model", type=str, default="auto", help="æ¨¡å‹å¤§å°ï¼ˆå·²åºŸå¼ƒï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶ï¼‰")
    parser.add_argument("--device", type=str, default="cpu", help="è®¾å¤‡ï¼ˆå·²åºŸå¼ƒï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶ï¼‰")
    parser.add_argument("--source-lang", type=str, default=None, help="æºè¯­è¨€")
    parser.add_argument("--target-lang", type=str, default="zh-CN", help="ç›®æ ‡è¯­è¨€")
    parser.add_argument("--chunk-duration", type=float, default=2.0, help="éŸ³é¢‘å—æ—¶é•¿ï¼ˆç§’ï¼‰")
    parser.add_argument("--config", type=str, default="model_config.json", help="é…ç½®æ–‡ä»¶è·¯å¾„")
    
    args = parser.parse_args()
    
    service = SystemAudioSubtitleService(
        model_size=args.model,
        target_lang=args.target_lang,
        source_lang=args.source_lang,
        chunk_duration=args.chunk_duration,
        config_file=args.config
    )
    
    try:
        service.start()
    except KeyboardInterrupt:
        logger.info("ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"ç¨‹åºè¿è¡Œå‡ºé”™: {e}", exc_info=True)
    finally:
        service.stop()


if __name__ == "__main__":
    # PyInstalleræ‰“åŒ…åœ¨Windows/macOSä¸‹éœ€è¦æ­¤è°ƒç”¨æ¥æ”¯æŒmultiprocessing
    multiprocessing.freeze_support()
    main()
