#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¯­éŸ³è½¬æ–‡å­—æœåŠ¡å±‚
è´Ÿè´£ç®¡ç†è¯­éŸ³è¯†åˆ«æ¨¡å‹ï¼Œæä¾›ç»Ÿä¸€çš„è¯­éŸ³è½¬æ–‡å­—æ¥å£
"""
import logging
import platform
from typing import Optional, Tuple
import numpy as np

from models.model_manager import ModelManager
from models.base_model import BaseSpeechToTextModel
from config_manager import ConfigManager

logger = logging.getLogger(__name__)


class STTService:
    """è¯­éŸ³è½¬æ–‡å­—æœåŠ¡"""
    
    def __init__(self, config_file: str = "model_config.json"):
        """
        åˆå§‹åŒ–è¯­éŸ³è½¬æ–‡å­—æœåŠ¡
        
        Args:
            config_file: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config_manager = ConfigManager(config_file)
        self.model: Optional[BaseSpeechToTextModel] = None
        self.current_model_name = None
    
    def initialize(self, model_name: Optional[str] = None) -> bool:
        """
        åˆå§‹åŒ–æ¨¡å‹
        
        Args:
            model_name: æ¨¡å‹åç§°ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é…ç½®ä¸­çš„å½“å‰æ¨¡å‹
            
        Returns:
            æ˜¯å¦åˆå§‹åŒ–æˆåŠŸ
        """
        if model_name is None:
            model_name = self.config_manager.get_current_model()
        
        model_config = self.config_manager.get_model_config(model_name)
        
        if not model_config:
            logger.error(f"âŒ æ— æ³•åŠ è½½æ¨¡å‹é…ç½®: {model_name}")
            # å›é€€åˆ°é»˜è®¤whisperé…ç½®
            model_name = "whisper"
            model_config = self.config_manager.get_model_config("whisper")
            if not model_config:
                logger.error("âŒ æ— æ³•åŠ è½½é»˜è®¤æ¨¡å‹é…ç½®")
                return False
        
        model_type = model_config.get("type", model_name)
        logger.info(f"ğŸš€ åˆå§‹åŒ–æ¨¡å‹: {model_name} (ç±»å‹: {model_type})")
        
        # å¦‚æœæ˜¯whisperæ¨¡å‹ï¼Œéœ€è¦è‡ªåŠ¨æ£€æµ‹è®¾å¤‡é…ç½®
        if model_type == "whisper":
            self._auto_config_whisper(model_config)
        
        # ä½¿ç”¨æ¨¡å‹ç®¡ç†å™¨åˆ›å»ºæ¨¡å‹
        self.model = ModelManager.create_model(model_type, model_config)
        
        if not self.model:
            logger.error(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {model_name}")
            return False
        
        self.current_model_name = model_name
        logger.info("âœ… è¯­éŸ³è½¬æ–‡å­—æœåŠ¡å°±ç»ª")
        return True
    
    def _auto_config_whisper(self, model_config: dict):
        """è‡ªåŠ¨é…ç½®Whisperæ¨¡å‹å‚æ•°"""
        system = platform.system()
        
        # è‡ªåŠ¨æ£€æµ‹è®¾å¤‡
        if "device" not in model_config or model_config["device"] == "auto":
            if system == "Darwin":
                logger.info("ğŸ’» ç³»ç»Ÿ: macOS (Apple Silicon)")
                model_config["device"] = "mps"
                model_config["compute_type"] = "int8"
                model_config["cpu_threads"] = 4
            elif system == "Windows":
                if self._check_cuda():
                    logger.info("ğŸš€ ç³»ç»Ÿ: Windows (CUDAåŠ é€Ÿ)")
                    model_config["device"] = "cuda"
                    model_config["compute_type"] = "float16"
                    model_config["cpu_threads"] = 0
                else:
                    logger.info("ğŸ’» ç³»ç»Ÿ: Windows (CPU)")
                    model_config["device"] = "cpu"
                    model_config["compute_type"] = "int8"
                    model_config["cpu_threads"] = 4
            elif system == 'Linux':
                model_config["device"] = "cuda"
                model_config["compute_type"] = "int8"
                model_config["cpu_threads"] = 4
        
        # è‡ªåŠ¨é€‰æ‹©æ¨¡å‹å¤§å°
        if model_config.get("model_size") == "auto":
            system = platform.system()
            if system == "Windows" and model_config.get("device") == "cuda":
                model_config["model_size"] = "deepdml/faster-whisper-large-v3-turbo-ct2"
            else:
                model_config["model_size"] = "small"
    
    def _check_cuda(self) -> bool:
        """æ£€æŸ¥CUDAæ˜¯å¦å¯ç”¨"""
        try:
            import ctypes
            ctypes.cdll.LoadLibrary('nvcuda.dll')
            return True
        except:
            return False
    
    def switch_model(self, model_name: str) -> bool:
        """
        åˆ‡æ¢æ¨¡å‹
        
        Args:
            model_name: æ–°æ¨¡å‹åç§°
            
        Returns:
            æ˜¯å¦åˆ‡æ¢æˆåŠŸ
        """
        logger.info(f"ğŸ”„ åˆ‡æ¢æ¨¡å‹: {model_name}")
        
        # ä¿å­˜æ—§æ¨¡å‹
        old_model = self.model
        
        # è·å–æ–°æ¨¡å‹é…ç½®
        model_config = self.config_manager.get_model_config(model_name)
        if not model_config:
            logger.error(f"âŒ æ— æ³•åŠ è½½æ¨¡å‹é…ç½®: {model_name}")
            return False
        
        model_type = model_config.get("type", model_name)
        
        # å¦‚æœæ˜¯whisperæ¨¡å‹ï¼Œè‡ªåŠ¨é…ç½®
        if model_type == "whisper":
            self._auto_config_whisper(model_config)
        
        # åˆ›å»ºæ–°æ¨¡å‹
        new_model = ModelManager.create_model(model_type, model_config)
        if not new_model:
            logger.error(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {model_name}")
            return False
        
        # åˆ‡æ¢æ¨¡å‹
        if old_model:
            try:
                old_model.cleanup()
            except Exception as e:
                logger.warning(f"æ¸…ç†æ—§æ¨¡å‹æ—¶å‡ºé”™: {e}")
        
        self.model = new_model
        self.current_model_name = model_name
        self.config_manager.set_current_model(model_name)
        logger.info(f"âœ… æ¨¡å‹åˆ‡æ¢æˆåŠŸ: {model_name}")
        return True
    
    def transcribe(
        self,
        audio_data: np.ndarray,
        sample_rate: int = 16000,
        language: Optional[str] = None,
        prompt: str = ""
    ) -> Tuple[Optional[str], Optional[str], float]:
        """
        è½¬å½•éŸ³é¢‘æ•°æ®
        
        Args:
            audio_data: éŸ³é¢‘æ•°æ® (numpy array, float32)
            sample_rate: é‡‡æ ·ç‡
            language: æºè¯­è¨€ä»£ç ï¼ˆå¯é€‰ï¼ŒNoneè¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹ï¼‰
            prompt: æç¤ºæ–‡æœ¬ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            (text, detected_language, cost_time)
            - text: è½¬å½•çš„æ–‡æœ¬ï¼Œå¦‚æœå¤±è´¥è¿”å›None
            - detected_language: æ£€æµ‹åˆ°çš„è¯­è¨€ä»£ç ï¼Œå¦‚æœå¤±è´¥è¿”å›None
            - cost_time: å¤„ç†è€—æ—¶ï¼ˆç§’ï¼‰
        """
        if not self.model:
            logger.error("æ¨¡å‹æœªåˆå§‹åŒ–")
            return None, None, 0.0
        
        try:
            text, detected_lang, cost = self.model.transcribe(
                audio_data,
                sample_rate=sample_rate,
                language=language,
                prompt=prompt
            )
            
            if text:
                logger.info(f"ğŸ‘‚ åŸæ–‡ [{detected_lang}][{cost:.2f}s]: {text}")
            
            return text, detected_lang, cost
        except Exception as e:
            logger.error(f"æ¨ç†é”™è¯¯: {e}")
            return None, None, 0.0
    
    def get_available_models(self) -> list:
        """è·å–æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
        return self.config_manager.get_available_models()
    
    def get_current_model(self) -> Optional[str]:
        """è·å–å½“å‰ä½¿ç”¨çš„æ¨¡å‹åç§°"""
        return self.current_model_name
    
    def is_available(self) -> bool:
        """æ£€æŸ¥æœåŠ¡æ˜¯å¦å¯ç”¨"""
        return self.model is not None and self.model.is_available()
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.model:
            try:
                self.model.cleanup()
            except Exception as e:
                logger.warning(f"æ¸…ç†æ¨¡å‹æ—¶å‡ºé”™: {e}")
            finally:
                self.model = None

